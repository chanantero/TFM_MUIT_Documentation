WFS theory is based on a propagation model where the acoustic field is generated by punctual primary sources and the cancellation field is generated by punctual monopole secondary sources, everything in an homogeneous media and free-space condition, and the location of every source is perfectly known.

A real situation, as the one we find in a listening room with real loudspeakers, is very different. A great variety of phenomena not contemplated by the WFS simple model occur: reflections, diffractions produced by obstacles, loudspeakers are not punctual sources so the near-field does not follow the far-field approximation, the directivity is not the one of an ideal monopole and depends on the frequency, the frequency response of loudspeakers is not flat, which would not be a problem if it was the same for every loudspeaker, but it might actually be very different from one to the other, their exact locations are not accurately known, non-linearities, etc.

All these differences influence the way the acoustic waves propagate, and in general, they worsen the performance in a real situation. Experimental measures help us understand how this not contemplated differences limit the possibilities of using WFS in the real world. In order to find a connection between the real and ideal situation, let's use a model of what is happening. In a real situation, all we can certainly know is that, if we transmit a signal through a loudspeaker and we measure at some point with a microphone, we receive a modified version of the signal. That modification depends on all the conditions previously mentioned (multiple reflections, etc.), and together they form what is often called acoustic path. An acoustic path between a loudspeaker and a point of measure acts as a filter characterized by an impulse response (time domain) or frequency response (frequency domain).

The relation between the transmitted signals and the received ones in the frequency domain is:
\begin{equation}
\Field[noValue][frequency][vector](f) = \AcPath[mat](f) \vec{\signal[nothing][frequency]}(f) ,
\end{equation}
where $\Field[noValue][frequency][vector] = [\Field[noValue][frequency][scalar]_1, \Field[noValue][frequency][scalar]_2, ..., \Field[noValue][frequency][scalar]_\numMeasPoints]^T$ ($\numMeasPoints$ is the number of points of measure) is the acoustic pressure vector, $\vec{\signal[nothing][frequency]} = [\signal[nothing][frequency]_1, \signal[nothing][frequency]_2, ..., \signal[nothing][frequency]_\numSources]^T$ ($\numSources$ is the number of loudspeakers) is the transmitted signals vector, and $\AcPath[mat]_{(\numMeasPoints \times \numSources)}$ is a matrix whose $(m,n)$-th element is the frequency response of the acoustic path between the $n$-th loudspeaker and the $m$-th point of measure.

When we differentiate the noise sources and the WFS array sources:
\begin{multline}
\Field[noValue][frequency][vector](f)
= \left. \begin{cases}
\vec{\signal[nothing][frequency]} = 
\begin{bmatrix}
\vec{\signal[wfs][frequency]} \\
\vec{\signal[ns][frequency]}
\end{bmatrix} \\
\AcPath[mat] =
\begin{bmatrix}
\AcPath[mat][WFS], & \AcPath[mat][NS]
\end{bmatrix}
\end{cases} \right\} \\
 = \AcPath[mat][NS](f) \vec{\signal[ns][frequency]}(f) + \AcPath[mat][WFS](f) \vec{\signal[wfs][frequency]}(f)
 = \Field[ns][frequency][vector](f) + \Field[wfs][frequency][vector](f),
\end{multline}
where $\Field[ns][frequency][vector] = [\Field[ns][frequency][scalar][1], \Field[ns][frequency][scalar][2], ..., \Field[ns][frequency][scalar][\numMeasPoints]]^T$, $\Field[wfs][frequency][vector] = [\Field[wfs][frequency][scalar][1], \Field[wfs][frequency][scalar][2], ..., \Field[wfs][frequency][scalar][\numMeasPoints]]^T$, $\vec{\signal[ns][frequency]} = [\signal[ns][frequency]_1, \signal[ns][frequency]_2, ..., \signal[ns][frequency]_{\numNS}]^T$ ($\numNS$ is the number of noise sources), $\vec{\signal[wfs][frequency]} = [\signal[wfs][frequency]_1, \signal[wfs][frequency]_2, ..., \signal[wfs][frequency]_{\numWFS}]^T$ ($\numWFS$ is the number of secondary sources) and $\AcPath[mat][NS]$ and $\AcPath[mat][WFS]$ are the acoustic path matrices of the noise sources and WFS secondary source array respectively. If the cancellation is successful, $\Field[ns][frequency][vector](f) \approx -\Field[wfs][frequency][vector](f)$ and so, $\Field[noValue][frequency][vector]$ becomes really small.

The signal reproduced by the secondary loudspeakers $\vec{\signal[wfs][frequency]}$ depends on the noise source signals $\vec{\signal[ns][frequency]}$. Specifically, each secondary source filters the noise source signals, as it was expressed in \autoref{rayleigh2_5Dsignal} and rewritten here:
\begin{multline}
\signal[wfs][frequency](f) = \signal[nsVirt][frequency](f) \frac{g \cos\normPrimaryPropAngleSection}{\sqrt{\distLinePrimSource}}
e^{-j k \distLinePrimSource} \sqrt{\frac{jk}{2\pi}} = \\
\left\{
\signal[nsVirt][frequency](f) = -\signal[ns][frequency] \rightarrow
H(f) = -\frac{g \cos\normPrimaryPropAngleSection}{\sqrt{\distLinePrimSource}}
e^{-j k \distLinePrimSource} \sqrt{\frac{jk}{2\pi}}
\right\} = \signal[ns][frequency](f) H(f).
\end{multline}
Expressed as a matrix multiplication:
\begin{equation}
\vec{\signal[wfs][frequency]} = \myMatrix{H} \vec{\signal[ns][frequency]},
\end{equation}
where $\myMatrix{H}_{\numWFS \times \numNS}(f)$ is a matrix where the $(m,n)$-th element is the filter frequency response that the $m$-th array loudspeaker applies to the $n$-th noise source.

In the model assumed by WFS theory (free-space conditions, ideal monopole point sources), the acoustic path response between a source and a point of measure separated by a distance $d$ is:
\begin{equation}
a(f) = \frac{e^{-j k d}}{d}.
\end{equation}
This allows us to construct $\AcPath[mat]'(f)$, the acoustic path response matrix for ideal conditions. The $(m,n)$-th element would be 
\begin{equation}
a_{m,n}(f) = \frac{e^{-j k d_{m,n}}}{d_{m,n}},
\end{equation}
where $d_{m,n}$ is the distance between the $n$-th loudspeaker and the $m$-th point of measure.

Under these conditions, good cancellation levels can be achieved. The actual $\AcPath[mat]$ includes all sorts of variations, as we saw, so one could expect the experimental result be much worse than what theory predicts. However, a way of making this model more realistic is by adding a variable that accounts for the possible sound volume difference between the noise source and the secondary loudspeaker array. This is useful because in the listening room we generate the noise signal with a loudspeaker. Unlike the secondary array loudspeakers, which were all adjusted to have similar behaviour, the noise loudspeaker volume can be independently adjusted manually. If we change it for another loudspeaker, the volume might be actually very different. This introduces an unknown variable that definitely affects cancellation, but it's really easy to model and compensate.

Basically, regarding the volume of the source as a separate variable when dealing with real loudspeakers, force us to differentiate between the digital signal in arbitrary units $\signal[nothing][frequency]$, and the real signal in acoustic pressure units (for example, Pascals) $\soundVolume \signal[nothing][frequency]$, where $\soundVolume$ is the sound volume of the loudspeaker that transforms arbitrary units in pressure units. This term goes then included in the acoustic path matrix $\AcPath[mat]$, where the $n$-th column is multiplied by the volume associated to the $n$-th loudspeaker. Since we consider that all loudspeakers of the secondary array are well calibrated and, for simplification purposes, also considering all noise loudspeakers have the same volume:
\begin{equation}
\Field[noValue][frequency][vector]
= (\soundVolume[ns]\AcPath[mat][NS]' + \soundVolume[wfs]\AcPath[mat][WFS]'\myMatrix{H}) \vec{\signal[ns][frequency]},
\end{equation}
where $\AcPath[mat][NS]'$ and $\AcPath[mat][WFS]'$ are the ideal acoustic path matrices when the volume term is not included. This means that $\AcPath[mat][NS] = \soundVolume[ns]\AcPath[mat][NS]'$ and $\AcPath[mat][WFS] = \soundVolume[wfs]\AcPath[mat][WFS]'$.

In order to perform cancellation, we must compensate for this volume difference by multiplying the amplitude of cancellation signals by $\globalCorrectionFactor = \soundVolume[ns]/\soundVolume[wfs]$. It can be estimated after measures or if we know the acoustic path responses by finding, for example, the real number $\correctionFactor$ that optimizes next expression:
\begin{equation}
\globalCorrectionFactor = \min_\correctionFactor \norm{\Field[wfs][frequency][vector]\correctionFactor + \Field[ns][frequency][vector]}^2 = \min_\correctionFactor \norm{(\AcPath[mat][NS] + \AcPath[mat][WFS]\myMatrix{H}\correctionFactor)\vec{\signal[ns][frequency]}}^2 = -\frac{\Re\left(\scalarProd{\Field[wfs][frequency][vector]^*}{\Field[ns][frequency][vector]}\right)}{\norm{\Field[wfs][frequency][vector]}^2}
\end{equation}
It is not the only way we can experimentally estimate this number, but it is a simple and useful way. By compensating the volume difference, at least we can measure WFS performance as if no volume difference was present.

Measures...

The cancellation when the optimum amplitude escalation has be found is:

Reflection about the models paradigm I just thought about in the kitchen.
What variables to inlcude depend on what we consider cheating or true WFS. Achieving silence on a microphone is easy by solving the linear system, but it's not WFS. That is cheating. What are we willing to consider as WFS or not?
