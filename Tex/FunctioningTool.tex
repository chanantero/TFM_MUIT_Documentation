In order to test the possibilities of WFS applied to cancellation of noise in the anechoic chamber, an appropriate software tool is required. The development of that tool, called \textit{WFSTool} and written in Matlab, has been the result of this thesis.

The main capability of \textit{WFSTool} is to play a sinusoidal signal of a desired frequency $f$ through one or more loudspeakers that will act as noise sources and, at the same time, play through each loudspeaker of the WFS array a sinusoidal signal of the same frequency $f$ but with different amplitudes and phases, so the interference of the acoustic field generated by the noise sources and the WFS array interfere destructively, in the ideal case. The acoustic field will be recorded by microphones located in the area of interest, so then can be analysed. To understand how the program works, we are going to cover the different blocks that are executed during the generation and reproduction of the signals.

%\begin{figure}
%	\centering
%	\def\svgwidth{1\columnwidth}
%	\graphicspath{{Img/}}
%	\input{Img/WFSToolSchemeReport_prueba.pdf_tex}
%	\caption{WFSTool scheme}
%	\label{figprueba}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\def\svgwidth{1\columnwidth}
%	\graphicspath{{Img/}}
%	\input{Img/WFSToolSchemeReport.pdf_tex}
%	\caption{WFSTool scheme}
%	\label{figWFSToolScheme2}
%\end{figure}

\begin{figure}
	\centering
	\includegraphics[height=0.5\textwidth,page=2]{./Img/WFSToolSchemeReport_definitive.pdf}
	\caption{WFSTool scheme}
	\label{figWFSToolScheme}
\end{figure}

\section{Setup of the scenario}
The starting point is the set up of relevant parameters in the mathematical modelling of the scenario, as described in \autoref{TheoreticalModelLabel}.

We need to set, at first, the properties of the WFS array. This is, the position $\Pos[mat][WFS]$ (3D coordinates) of all loudspeakers and their radiation patterns $\Diag[vec][WFS]$, which are not numeric values but functions that accept a direction as input argument. In the case of the anechoic chamber we use, there are 96 loudspeakers distributed as an polygon as showed in \autoref{WFSdistribution}. For simplification purposes, we have assumed that they are isotropic sources, but the software can work with any radiation pattern.

The same must be done with the microphones, that will also have a position $\Pos[mat][micro]$, and radiation pattern $\Diag[vec][micro]$.

Once we have modelled the WFS and microphone array, we need to set the properties of the noise sources. They will also have a position $\Pos[mat][NS]$, and radiation pattern $\Diag[vec][NS]$. But also the complex coefficient of the transmitted signal $\coef[scalar][NS]$, as well as the virtual one $\coef[scalar][NS]<virtual>$, this is, the coefficient that we \textit{assume} the noise source is transmitting when applying the WFS calculation. The reason both values are stored in different variables is because depending on the type of experiment or simulation, both coefficients can be equal or different. Differentiating both values adds some flexibility that can be useful in some cases.

The relation between the transmitted coefficients and the received ones is characterized by the frequency responses $\AcPath[mat][WFS]$ and $\AcPath[mat][NS]$. The user can set those properties manually, but could also use the option of calculating it theoretically based on the model explained at \autoref{TheoreticalModelLabel}.

All these variables are particularized for a given frequency that will be a global variable.

Finally, in case we are using the program with a real audio device, we must specify what audio channels will be used to play the signals and to record the generated acoustic field.
 
\section{WFS calculation and simulation}
\label{WFScalculation}

Once the scenario is theoretically defined, two basic operations can be done. The first one is the calculation of the appropriate complex coefficients that will create a field for the noise cancellation. We use the WFS equations of \autoref{WFSexplanation}, which are particularized for the loudspeaker array in the anechoic chamber, and then some type of optimization (\autoref{optimization}) that the user can choose providing some parameters to the program.

The next obvious operation is the simulation, this is, the calculation of the received coefficients by the microphones with a simple matrix operation (\autoref{transEqMatrixRep1}): $\coef[vec][micro] = \AcPath[mat][WFS] \coef[vec][WFS] + \AcPath[mat][NS] \coef[vec][NS]$.

\section{Reproduction and Recording}
The program is capable of handling reproduction and recording of audio signals. This step is delicate because the software must communicate with the proper audio driver and several parameters must be configured. The class \textit{ReproductorRecorder} has been developed in Matlab in order to manage all reproduction issues and make the communication with audio drivers transparent to the user. It uses exclusively internal Matlab functions, without the help of any external library. Although it can play signals from different origins (audio files, variables, parametric signals) on multiple devices simultaneously, apply real-time attenuation and delaying, and other features, the use that is given in the program \textit{WFSTool} is relatively simple.

All we need are sinusoidal signals that are reproduced for a given duration (we will call it a pulse), at the specified frequency and with the amplitude and phase stored in complex form in $\coef[vec][WFS]$ and $\coef[vec][NS]$. A signal can be a concatenation of multiple sinusoidal pulses with different duration, frequency, amplitude or phase.

%Therefore, a signal is perfectly defined by a 3D array \variable{pulseCoefMat}, a 2D array \variable{pulseLimits}, and 2 vectors (\variable{channels} and \variable{frequencies}). The size of the matrix is ($numPulses$, $numChannels$, $numFrequencies$), and the ($p$, $ch$, $f$)-th element is the complex coefficient of the $p$-th pulse, reproduced by the \variable{channels[ch]} channel in the playing device, with frequency \variable{frequencies[f]}. The starting end ending time of the pulses are \variable{pulseLimits[p, 1]} and \variable{pulseLimits[p, 2]} respectively.

Therefore, this type of signal is defined by a 3D array $\myMatrix{C}_{(\mathit{numP} x \mathit{numCh} x \mathit{numF})}$, a 2D array $\myMatrix{L}_{(\mathit{numP} x 2)}$, and 2 vectors $\vec{Ch}_{(\mathit{numCh} x 1)}$ and $\vec{F}_{(\mathit{numF} x 1)}$), where $\mathit{numP}$, $\mathit{numCh}$ and $\mathit{numF}$ are the number of pulses, channels and frequencies respectively. The ($p$, $ch$, $f$)-th element of $\myMatrix{C}$ is the complex coefficient of the $p$-th pulse, reproduced by the ($\vec{Ch}_{\mathit{ch}}$)-th channel in the playing device, with frequency $\vec{F}_f$. The starting end ending time of the pulses are $\myMatrix{L}_{p, 1}$ and $\myMatrix{L}_{p, 2}$ respectively. Internally, all these variables are stored as numerical arrays: \variable{pulseCoefMat} for $\myMatrix{C}$, \variable{pulseLimits} for $\myMatrix{L}$, \variable{channels} for $\vec{Ch}$ and \variable{frequencies} for $\vec{F}$.


A way of expressing it is that the signal of the $ch$-th channel is:
\begin{equation}
x_{ch}(t) = \sum_{f = 1}^{numF} \sum_{p = 1}^{numP} W\left(\frac{t - \tau_p}{T_p}\right)
\Re \left\{ \myMatrix{C}_{(p,ch,f)} e^{j 2 \pi \vec{F}_f t} \right\}
\end{equation}

\begin{description}
	\item[$W(t)$] Window function
	\item[$\tau_p$] Delay of the midpoint $p$-th pulse: $\frac{\myMatrix{L}_{p, 1} + \myMatrix{L}_{p, 2}}{2}$
	\item[$T_p$] Duration of the $p$-th pulse: $\myMatrix{L}_{p, 1} + \myMatrix{L}_{p, 2}$
\end{description}

%\begin{description}
%	\item[$\myMatrix{C}$] Pulse coefficient matrix \variable{pulseCoefMat}
%	\item[$\vec{F}$] Frequency vector \variable{frequencies}
%	\item[$W(t)$] Window function
%	\item[$numF$] Number of frequencies $numFrequencies$
%	\item[$numP$] Number of pulses $numPulses$
%	\item[$\tau_p$] Delay of the midpoint $p$-th pulse: $\frac{\text{\variable{pulseLimits[p, 1] + pulseLimits[p, 2]}}}{2}$
%	\item[$T_p$] Duration of the $p$-th pulse: $\text{\variable{pulseLimits[p, 2] - pulseLimits[p, 1]}}$
%\end{description}

The window $W$ can be a rectangular function as defined in \autoref{rectFunc}. However, other functions with a different spectrum can be used in order facilitate the detection. The program uses a modification of the Hanning window to reduce the magnitude of side lobes. %(\autoref{HanningSpectrumComparison}).
\begin{equation}
\Pi(t) = \left\{ \begin{array}{lcc}
0 &   if  & |t| > 1/2 \\
1 &  if & |t| \leq 1/2 \\
\end{array} \right.
\label{rectFunc}
\end{equation}

For example, the next configuration
\begin{gather*}
\text{\variable{pulseCoefMat[:, :, 1]}} = 
\begin{bmatrix}
	i & 0 \\
	0 & 1 \\
	2 & 0 \\
	0 & -0.5 \\
\end{bmatrix}
\quad
\text{\variable{pulseCoefMat[:, :, 2]}} = 
\begin{bmatrix}
	-i & 0 \\
	0 & 0 \\
	0 & 1 \\
	0 & 0 \\
\end{bmatrix}\\
\text{\variable{pulseLimits}} =
\begin{bmatrix}
	0 & 2 \\
	3 & 4 \\
	5 & 7 \\
	9 & 10 \\
\end{bmatrix}
\quad
\text{\variable{channels}} =
\begin{bmatrix}
	2 \\
	1 \\
\end{bmatrix}
\quad
\text{\variable{frequencies}} =
\begin{bmatrix}
	2 \\
	0.25 \\
\end{bmatrix}
\end{gather*}

gives as a result the signal in the \reffig{examplePulseSignal}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.4\textwidth]{Img/completePulseSignalRectWindow.eps}
	\caption[Pulse Signal]{Example of pulse signal}
	\label{examplePulseSignal}
\end{figure}

Once the signal has been defined and constructed, it is played and recorded by the class \class{ReproductorRecorder}. The recorded signal is of course different from the transmitted one. It has been modified by the response of loudspeakers and microphones, the noise, the directivity, position of objects, etc. However, we must detect the pulses in order to calculate how the amplitude and phase has been modified. So, how is the detection performed?

\subsection{Detection of pulses}
We take advantage of the fact that we know what the transmitted signal is. First, we calculate the IQ signal, this is, the low frequency signal that modulates the carrier, whose frequency we know. The relation of the IQ signal and the original one is:
\begin{equation}
x(t) = \Re\{ e^{j 2 \pi f t} x_{IQ}(t) \} = |x_{IQ}(t)| \cos(2 \pi f t + \phi(t))
\label{IQcondition}
\end{equation}

It can be done by applying a band-pass filter around the desired frequency and down-converting the resulting signal.

Now that we have the modulating signal $x_{IQ}(t)$, we need to detect where the pulses are. Their amplitude and phase can present distortions due to noise and non-linear effects, but the duration and delay between them is going to be approximately the same. Hence, we can generate a mask that is set to one when there is a pulse in the original signal and to zero otherwise, cross-correlate it by $x_{IQ}(t)$, and find the lag that returns the maximum value of correlation. To find the complex coefficients of pulses (amplitude and phase), we just perform the mean of each pulse.

The whole process is summarized in \autoref{detectionScheme}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{Img/detectionScheme.pdf}
	\caption[Detection Scheme]{Scheme of the detection}
	\label{detectionScheme}
\end{figure}

This reproduction and detection capability is useful as a tool for calculating, for example, the experimental acoustic paths, or for testing if the simulated scenario has a correspondence with the real one.